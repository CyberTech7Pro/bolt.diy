version: "3.9"

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: bolt-ai-production           # usa a stage de produção do seu Dockerfile
      args:
        VITE_LOG_LEVEL: info
    image: bolt-ai:production
    command: ["pnpm","run","dockerstart"]  # conforme o CMD da stage de produção
    ports:
      - "5173:5173"                        # a imagem expõe 5173; mantenha
    env_file: .env.local                   # variáveis sensíveis
    environment:
      NODE_ENV: "production"
      PORT: "5173"
      RUNNING_IN_DOCKER: "true"
      DEFAULT_NUM_CTX: "${DEFAULT_NUM_CTX:-32768}"

      # URLs públicas (alguns forks/rotas usam isso)
      NEXT_PUBLIC_BASE_URL: "https://bolt.ianeuralinker.com"
      NEXTAUTH_URL: "https://bolt.ianeuralinker.com"

      # Provedores de LLM (preencha no .env.local ou direto aqui)
      GROQ_API_KEY: "${GROQ_API_KEY}"
      HuggingFace_API_KEY: "${HuggingFace_API_KEY}"
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"
      OPEN_ROUTER_API_KEY: "${OPEN_ROUTER_API_KEY}"
      GOOGLE_GENERATIVE_AI_API_KEY: "${GOOGLE_GENERATIVE_AI_API_KEY}"
      OLLAMA_API_BASE_URL: "${OLLAMA_API_BASE_URL}"
      XAI_API_KEY: "${XAI_API_KEY}"
      TOGETHER_API_KEY: "${TOGETHER_API_KEY}"
      TOGETHER_API_BASE_URL: "${TOGETHER_API_BASE_URL}"
      AWS_BEDROCK_CONFIG: "${AWS_BEDROCK_CONFIG}"

    extra_hosts:
      - "host.docker.internal:host-gateway"

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:5173/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 20s

      retries: 12
      start_period: 20s
